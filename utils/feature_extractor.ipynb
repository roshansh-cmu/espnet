{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5882f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-jo38tpk5\n",
      "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-jo38tpk5\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
      "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!conda install av')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6e6b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 17 17:59:16 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    41W / 300W |      3MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d583761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.io.video import read_video,read_video_timestamps\n",
    "import clip\n",
    "from kaldiio import WriteHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "688fb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(video_path, clip_model, preprocess_transforms, frame_rate, batch_size):\n",
    "    \n",
    "    \n",
    "    step = int(v_fps//frame_rate)\n",
    "    print(step)\n",
    "    #Preprocess Images\n",
    "    vid = vid[0: vid.shape[0]:step,::]\n",
    "    features = torch.zeros((vid.shape[0], 768))\n",
    "    \n",
    "    num_frames = vid.shape[0] \n",
    "    feature_sets = []\n",
    "    \n",
    "    for i in range(0, num_frames, batch_size):        \n",
    "        for j in range(i, i+batch_size):\n",
    "            \n",
    "                features = torch.zeros((vid.shape[0], 768))\n",
    "                frame = vid[j]\n",
    "                v_image = T.ToPILImage()(frame)\n",
    "                v_processed = preprocess_transforms(v_image)\n",
    "                v_processed = v_processed.unsqueeze(0).to('cuda')\n",
    "                image_features = clip_model.encode_image(v_processed)\n",
    "                features[i] = image_features\n",
    "                \n",
    "        feature_sets.append(features)\n",
    "        \n",
    "    return feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ccdf5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(start_frame,batch_size,video_length,clip_model,preprocess_transforms,vid):\n",
    "    features = []\n",
    "    for i in range(start_frame, start_frame+batch_size):\n",
    "        if i> video_length:\n",
    "            break\n",
    "        \n",
    "        frame = vid[i]\n",
    "        v_image = T.ToPILImage()(frame)\n",
    "        v_processed = preprocess_transforms(v_image)\n",
    "        v_processed = v_processed.unsqueeze(0).to('cuda')\n",
    "        image_features = clip_model.encode_image(v_processed)\n",
    "        features.append(image_features)\n",
    "    return torch.cat(features).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc161311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aaac5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(inpt_f,out_f, out_path, dir_path,frame_rate,video_path_eshani):\n",
    "    \n",
    "    with open(inp_f,mode='r') as f:\n",
    "        \n",
    "        with WriteHelper(\n",
    "        \n",
    "        f\"ark,scp:{os.path.join(dir_path,out_f+'ark')},{out_path+'_'+'feature_set'+out_f+'scp'}\") as writer:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                #video_id, video_path = line.strip().split(\" \")\n",
    "                with torch.no_grad():\n",
    "                    vid, _,video_metadata = read_video(video_path_eshani, pts_unit = 'sec',output_format = \"TCHW\")\n",
    "                    _, v_fps = read_video_timestamps(video_path_eshani, pts_unit = 'sec')\n",
    "                    step = int(v_fps//frame_rate)\n",
    "\n",
    "                    vid = vid[0: vid.shape[0]:step,::]\n",
    "                    if torch.cuda.is_available():\n",
    "                        vid = vid.cuda()\n",
    "                    #features = torch.zeros((vid.shape[0], 768))\n",
    "\n",
    "                    num_frames = vid.shape[0]\n",
    "                    batch_size = 2\n",
    "\n",
    "                    for i in range(0, num_frames, batch_size):  \n",
    "                        features_batch = get_features(i,batch_size,num_frames,model,preprocess,vid)\n",
    "                        print(type(features_batch[0]))\n",
    "                        writer(\"batch_\"+str(int(i//batch_size)),features_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c85dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 17 18:00:03 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    54W / 300W |   1714MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     52274      C   ...wal/miniconda3/bin/python     1711MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdaf2cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'clear_cache'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear_cache\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'clear_cache'"
     ]
    }
   ],
   "source": [
    "torch.cuda.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b109ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-L/14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15ebab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/ocean/projects/iri120008p/roshansh/corpora/how2/all_videos/-ImHtlpQoGI.mp4'\n",
    "#features = get_features(0,12, 30, model, preprocess,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fa2862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported array type: float16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m frame_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43msave_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mframe_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [48], line 27\u001b[0m, in \u001b[0;36msave_features\u001b[0;34m(inpt_f, out_f, out_path, dir_path, frame_rate, video_path_eshani)\u001b[0m\n\u001b[1;32m     25\u001b[0m features_batch \u001b[38;5;241m=\u001b[39m get_features(i,batch_size,num_frames,model,preprocess,vid)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(features_batch[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m---> 27\u001b[0m \u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/kaldiio/highlevel.py:51\u001b[0m, in \u001b[0;36mWriteHelper.__call__\u001b[0;34m(self, key, array)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriteHelper has been already closed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43msave_ark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfscp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/kaldiio/matio.py:794\u001b[0m, in \u001b[0;36msave_ark\u001b[0;34m(ark, array_dict, scp, append, text, endian, compression_method, write_function)\u001b[0m\n\u001b[1;32m    792\u001b[0m             size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m write_array_ascii(fd, data, endian)\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 794\u001b[0m             size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# Write scp\u001b[39;00m\n\u001b[1;32m    797\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m append \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/kaldiio/matio.py:902\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fd, array, endian, compression_method)\u001b[0m\n\u001b[1;32m    900\u001b[0m     size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported array type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m size\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported array type: float16"
     ]
    }
   ],
   "source": [
    "inp_f = '/ocean/projects/cis220078p/akapoor1/project/espnet/egs2/how2_2000h/sum1/dump/fbank_pitch/dev5_test_sum/wav.scp'\n",
    "out_f = \"feats\"\n",
    "out_path = \"1\"\n",
    "dir_path = \"./\"\n",
    "frame_rate = 6\n",
    "import os\n",
    "save_features(inp_f,out_f, out_path, dir_path,frame_rate,video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
